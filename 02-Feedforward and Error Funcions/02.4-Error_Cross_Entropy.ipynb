{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b1a192",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Hay dos tipos cd Cross-Entropy, Binaria y Multiple, BCE o simplemente CE.\n",
    "\n",
    "Se usa cuando predices una probabilidad.\n",
    "\n",
    "Se puede calcular con logits o tras la FA, pero computacionalmente, es mas eficiente hacerlo con logits.\n",
    "\n",
    "\n",
    "Un logit es el resutlado de la red en la capa de clasificacion final antes la  de la funcion de activacion.\n",
    "\n",
    "¿Que hace?\n",
    "\n",
    "No mide “distancia”, sino verosimilitud.\n",
    "\n",
    "Penaliza más los errores muy confiados.\n",
    "\n",
    "Hace que el modelo aprenda a producir buenas probabilidades, no solo valores cercanos a 0 o 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638f1db",
   "metadata": {},
   "source": [
    "## BCE (Binary Cross-Entropy)\n",
    "\n",
    "Se usa cuando predices una probabilidad de clase (0 o 1)\n",
    "\n",
    "Clasificación binaria: salida de una Sigmoid.\n",
    "\n",
    "Es perro (1) o no es perro (0).\n",
    "\n",
    "Spam o no spam.\n",
    "\n",
    "Falla el sistema o no falla.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c0336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits (z):\n",
      " tensor([[ 0.2000],\n",
      "        [ 1.5000],\n",
      "        [-1.2000]])\n",
      "Probabilidades (σ(z)):\n",
      " tensor([[0.5498],\n",
      "        [0.8176],\n",
      "        [0.2315]])\n",
      "Shapes → logits: (3, 1) | y_true: (3, 1)\n",
      "\n",
      "Binary Cross-Entropy (manual): 0.42094483971595764\n",
      "BCE con probabilidades : 0.42094483971595764\n",
      "BCE con logits (estable): 0.42094483971595764\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === 1. Logits de ejemplo (salida cruda de la última capa, antes de la sigmoide) ===\n",
    "logits = torch.tensor([[0.2], [1.5], [-1.2]])  # (3,1) → valores antes de Sigmoid\n",
    "\n",
    "# === 2. Etiquetas reales ===\n",
    "y_true = torch.tensor([[0.0], [1.0], [0.0]])   # (3,1)\n",
    "\n",
    "# === 3. Probabilidades después de aplicar la Sigmoid ===\n",
    "probs = torch.sigmoid(logits)\n",
    "\n",
    "print(\"Logits (z):\\n\", logits)\n",
    "print(\"Probabilidades (σ(z)):\\n\", probs)\n",
    "print(\"Shapes → logits:\", tuple(logits.shape), \"| y_true:\", tuple(y_true.shape))\n",
    "\n",
    "# === 4. Cross-Entropy calculada a mano (usando probabilidades) ===\n",
    "# Fórmula: -[ y*log(p) + (1-y)*log(1-p) ]\n",
    "bce_manual = - (y_true * torch.log(probs) + (1 - y_true) * torch.log(1 - probs))\n",
    "bce_manual_mean = bce_manual.mean()\n",
    "\n",
    "print(\"\\nBinary Cross-Entropy (manual):\", bce_manual_mean.item())\n",
    "\n",
    "# === 5. Cross-Entropy con PyTorch ===\n",
    "# a) usando las probabilidades directamente\n",
    "bce_probs = F.binary_cross_entropy(probs, y_true)\n",
    "# b) usando los logits directamente (más estable)\n",
    "bce_logits = F.binary_cross_entropy_with_logits(logits, y_true)\n",
    "\n",
    "print(\"BCE con probabilidades :\", bce_probs.item())\n",
    "print(\"BCE con logits (estable):\", bce_logits.item())\n",
    "\n",
    "# === 6. Comprobación de equivalencia numérica aproximada ===\n",
    "assert torch.allclose(bce_probs, bce_logits, atol=1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60c4fa",
   "metadata": {},
   "source": [
    "## CE Multiple\n",
    "\n",
    "Es similar, pero para tareas de clasificacion con mas de 2 clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cee85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes → logits: (3, 3) | y_true: (3,)\n",
      "\n",
      "Probabilidades (Softmax):\n",
      " tensor([[0.6590, 0.2424, 0.0986],\n",
      "        [0.1086, 0.8025, 0.0889],\n",
      "        [0.0493, 0.0545, 0.8962]])\n",
      "\n",
      "Cross-Entropy (PyTorch): 0.24889366328716278\n",
      "Cross-Entropy (manual): 0.24889366328716278\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === 1. Logits de ejemplo (salida cruda antes del Softmax) ===\n",
    "# Supongamos 3 muestras (ya procesadas: logits antes de softmax) y 3 clases (cada fila = muestra)\n",
    "logits = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],   # muestra 1\n",
    "    [0.5, 2.5, 0.3],   # muestra 2\n",
    "    [0.1, 0.2, 3.0]    # muestra 3\n",
    "])\n",
    "\n",
    "# === 2. Etiquetas reales ===\n",
    "# En multiclase, los targets son índices enteros (0, 1, 2)\n",
    "y_true = torch.tensor([0, 1, 2])\n",
    "\n",
    "print(\"Shapes → logits:\", tuple(logits.shape), \"| y_true:\", tuple(y_true.shape))\n",
    "\n",
    "# === 3. Probabilidades después del Softmax (solo para inspección) ===\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(\"\\nProbabilidades (Softmax):\\n\", probs)\n",
    "\n",
    "# === 4. Cross-Entropy con PyTorch (logits → CE estable) ===\n",
    "ce_loss = F.cross_entropy(logits, y_true)\n",
    "print(\"\\nCross-Entropy (PyTorch):\", ce_loss.item())\n",
    "\n",
    "# === 5. Verificación manual (solo demostrativa, usando log-softmax) ===\n",
    "log_probs = torch.log_softmax(logits, dim=1)\n",
    "ce_manual = -log_probs[range(len(y_true)), y_true].mean()\n",
    "print(\"Cross-Entropy (manual):\", ce_manual.item())\n",
    "\n",
    "# === 6. Comprobación de equivalencia numérica ===\n",
    "assert torch.allclose(ce_loss, ce_manual, atol=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11028f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

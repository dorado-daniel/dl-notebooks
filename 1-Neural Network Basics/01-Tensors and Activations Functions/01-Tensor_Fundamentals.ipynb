{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa6fb33",
   "metadata": {},
   "source": [
    "# Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849a2b2",
   "metadata": {},
   "source": [
    "Un tensor es como un array de Numpy, pero con soporte para GPU y gradientes.+\n",
    "Los tensores son la unidad mínima de datos en deep learning.\n",
    "Todo modelo se reduce a operaciones tensoriales (suma, multiplicación, activación).\n",
    "Forward pass = aplicar una serie de transformaciones determinísticas sobre tensores.\n",
    "\n",
    "requires_grad=True activa el seguimiento para el backprop posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de78955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: cuda\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SETUP\n",
    "import torch\n",
    "\n",
    "#Seed para reproducibilidad, los pesos y biases son aleatorios\n",
    "#pero queremos que sean los mismos en cada run\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Usando:\", device)\n",
    "torch.cuda.get_device_name(0)\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55fda8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Datos de entrada (x) ===\n",
      "tensor([[ 90.,   3.],\n",
      "        [120.,   4.],\n",
      "        [ 60.,   2.]], device='cuda:0')\n",
      "\n",
      "=== Pesos (w) ===\n",
      "tensor([[0.8000],\n",
      "        [0.3000]], device='cuda:0')\n",
      "\n",
      "=== Bias (b) ===\n",
      "tensor([10.], device='cuda:0')\n",
      "\n",
      "=== Salida (y = x @ w + b) ===\n",
      "tensor([[ 82.9000],\n",
      "        [107.2000],\n",
      "        [ 58.6000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Declaramos tensores de entrada, pesos y bias en GPU.\n",
    "# Esto representa el núcleo matemático de una sola neurona (perceptrón lineal).\n",
    "\n",
    "# x tiene forma (3, 2):\n",
    "#   - 3 filas → 3 casas (3 muestras)\n",
    "#   - 2 columnas → 2 características por casa (tamaño, nº de habitaciones)\n",
    "# Estos datos vendrian de un dataset de casas.\n",
    "x = torch.tensor([\n",
    "    [90.0, 3.0],   # Casa 1\n",
    "    [120.0, 4.0],  # Casa 2\n",
    "    [60.0, 2.0]    # Casa 3\n",
    "], device=\"cuda\")\n",
    "\n",
    "# w tiene forma (2, 1):\n",
    "#   - 2 filas → un peso por cada característica de entrada\n",
    "#   - 1 columna → una neurona (una salida)\n",
    "# Supongamos que el tamaño influye más que el número de habitaciones.\n",
    "# Estos pesos serian random, pero los fijamos para el ejemplo.\n",
    "w = torch.tensor([\n",
    "    [0.8],  # peso asociado al tamaño\n",
    "    [0.3]   # peso asociado a las habitaciones\n",
    "], device=\"cuda\")\n",
    "\n",
    "# b tiene forma (1,):\n",
    "#   - un sesgo que ajusta la salida de todas las muestras.\n",
    "b = torch.tensor([10.0], device=\"cuda\")\n",
    "\n",
    "# operación lineal: y = x @ w + b\n",
    "#   - @ es el producto matricial\n",
    "#   - El bias se suma a cada fila del resultado\n",
    "y = x @ w + b\n",
    "\n",
    "print(\"=== Datos de entrada (x) ===\")\n",
    "print(x)\n",
    "print(\"\\n=== Pesos (w) ===\")\n",
    "print(w)\n",
    "print(\"\\n=== Bias (b) ===\")\n",
    "print(b)\n",
    "print(\"\\n=== Salida (y = x @ w + b) ===\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fab1ef",
   "metadata": {},
   "source": [
    "\n",
    "### Tensores aplicados a imagenes.\n",
    "Esto esta relacionado con el notebok 2-CNN-Color\n",
    "Nos ayudará a entender que hace.\n",
    "En especifico con la linea:\n",
    "\n",
    " x.sum(dim=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cac20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([2, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Creamos un tensor de 4D 2 imagenes, 3 canales, 2 filas y 2 columnas\n",
    "# [batch=2, canales=3, alto=2, ancho=2]\n",
    "\n",
    "#los pixeles se representan por la posicion de cada numero\n",
    "#Un unico canal se compone de 1 matriz 2x2\n",
    "#Un sample (imagen) son entonces 3 matrices: una por cada canal\n",
    "#Como la imagen es de 2x2, cada matriz tiene 2 filas y 2 columnas\n",
    "\n",
    "#Como tenemos 2 imagenes, tenemos 2 samples dentro de un batch\n",
    "x = torch.tensor([\n",
    "    [  # Imagen 1 (sample  1) una imagen tiene 3 dimensiones\n",
    "        [[1, 2],    # Primera fila de pixeles del canal R\n",
    "         [3, 4]],    # canal R\n",
    "\n",
    "        [[5, 6],\n",
    "         [7, 8]],    # canal G\n",
    "\n",
    "        [[9,10],\n",
    "         [11,12]]    # canal B\n",
    "    ],\n",
    "    [  # Imagen 2 (sample  2)\n",
    "        [[13,14], \n",
    "         [15,16]],   # canal R\n",
    "\n",
    "        [[17,18],\n",
    "         [19,20]],   # canal G\n",
    "\n",
    "        [[21,22],\n",
    "         [23,24]]    # canal B\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(\"shape:\", x.shape)   # [2, 3, 2, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f74164",
   "metadata": {},
   "source": [
    "Vamos a visualizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7862f25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionamos la primera imagen del batch\n",
    "img = x[0]  # shape [3, 2, 2]\n",
    "\n",
    "# Extraemos los tres canales individuales\n",
    "r = img[0]  # canal rojo\n",
    "g = img[1]  # canal verde\n",
    "b = img[2]  # canal azul\n",
    "\n",
    "# Mostramos los tres canales por separado\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "\n",
    "axs[0].imshow(r, cmap='Reds')\n",
    "axs[0].set_title('Canal R')\n",
    "axs[1].imshow(g, cmap='Greens')\n",
    "axs[1].set_title('Canal G')\n",
    "axs[2].imshow(b, cmap='Blues')\n",
    "axs[2].set_title('Canal B')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

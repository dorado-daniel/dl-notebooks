{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963f596c",
   "metadata": {},
   "source": [
    "# CNNs Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2faa6a4",
   "metadata": {},
   "source": [
    "Vamos a usar el DS MNIST.\n",
    "\n",
    "Como primer paso, convertiremos los pixeles de cada imagen a un tensor estabilizado entre 0 y 1 para poder usarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646aad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "images.shape: torch.Size([4, 1, 28, 28])\n",
      "labels: [6, 8, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "# Arranque: imports, dataset y primer batch (MNIST)\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Aqui convertimos las imagenes a tensores\n",
    "# Es decir, el valor de los pixeles pasa a estar entre 0 y 1\n",
    "# y el shape de las imagenes pasa a ser (C,H,W) (Canales, Alto, Ancho)\n",
    "\n",
    "transform = transforms.ToTensor()  # [0,1], shape (C,H,W)\n",
    "\n",
    "train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "loader = DataLoader(train, batch_size=4, shuffle=True)\n",
    "\n",
    "# Cogemos un batch de 4 imagenes\n",
    "images, labels = next(iter(loader))\n",
    "\n",
    "# Imprimimos el shape de las imagenes y las etiquetas\n",
    "print(\"images.shape:\", images.shape)   # esperado: ([4, 1, 28, 28])\n",
    "\n",
    "# Imprimimos las etiquetas\n",
    "print(\"labels:\", labels.tolist())\n",
    "\n",
    "# Comprobamos que el shape de las imagenes es el esperado\n",
    "assert images.ndim == 4 and images.shape[1] == 1 and images.shape[2] == 28 and images.shape[3] == 28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92890036",
   "metadata": {},
   "source": [
    "Vamos a dar un vistazo para entender mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a56b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canales: 1, Alto: 28, Ancho: 28\n",
      "Rango de píxeles: 0.000 a 1.000\n"
     ]
    }
   ],
   "source": [
    "images_cuda = images.to(device)\n",
    "one_image = images_cuda[0]\n",
    "\n",
    "C, H, W = one_image.shape\n",
    "\n",
    "#Podemos observar como solo hay un unico canal, que es el negro y blanco.\n",
    "#Si fuera algo a color, habria 3 canales (R, G, B)\n",
    "#Si ademas tuviera transparencia, habria 4 canales (R, G, B, A)\n",
    "\n",
    "\n",
    "print(f\"Canales: {C}, Alto: {H}, Ancho: {W}\")\n",
    "\n",
    "print(f\"Rango de píxeles: {one_image.min():.3f} a {one_image.max():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c59f0",
   "metadata": {},
   "source": [
    "Capa de Convolución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13a4f3",
   "metadata": {},
   "source": [
    "EL padding permite que los kernel tengan en cuenta más veces los pixeles de los bordes, al añadir un padding de 0s alrededor, el kernel tiene espacio para pasar mas veces por los pixeles de los bordes, un padding de 1 no reduce el tamaño de la imagen por ese motivo.\n",
    "\n",
    "VALID PADDING = 0 // No hay marco, la imagen se reduce.\n",
    "\n",
    "SAME PADDING = 1 // Hay marco, la imagen no se reduec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos la capa de convolución\n",
    "\n",
    "# in_channels = 1, porque es una imagen en blanco y negro\n",
    "# out_channels = 8, porque queremos 8 features (8 filtros)\n",
    "# kernel_size = 3, porque queremos un kernel de 3x3 px\n",
    "# padding = 1, porque queremos que la imagen siga teniendo el mismo tamaño\n",
    "# stride = 1, porque queremos que el kernel se desplace 1 px por vez\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1, stride=1, out_channels=8, kernel_size=3, padding=1)\n",
    "\n",
    "#Declaramos la capa de pooling\n",
    "pool = nn.MaxPool2d(2)\n",
    "\n",
    "#Pasamos las imagenes al dispositivo\n",
    "x = images  # (B, 1, 28, 28)\n",
    "x1 = F.relu(conv(x))\n",
    "print(\"Después de Conv+ReLU:\", x1.shape)\n",
    "x2 = pool(x1)\n",
    "print(\"Después de MaxPool:\", x2.shape)\n",
    "\n",
    "assert x2.shape == (4, 8, 14, 14)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

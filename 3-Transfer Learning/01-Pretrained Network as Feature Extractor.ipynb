{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a789dd2e",
   "metadata": {},
   "source": [
    "# Pretrained Network | Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5de52",
   "metadata": {},
   "source": [
    "El objetivo de esta sección es ver como implementar transfer-learning cuando tenemos una cantidad de datos disponible limitada, pero el dominio del objetivo es similar a la red que queremos usar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b9ab3",
   "metadata": {},
   "source": [
    "Congelaremos la parte de extracción de features de la red VGG16 entrenada en el dataset IMAGENET, y agregaremos nuestro propio clasificador, para después reentrenar la red con nuestro pequeño dataset.\n",
    "\n",
    "Otro de los objetivos será mostrar como preprocesar nuestros datos para conseguir entrenar una red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035397b9",
   "metadata": {},
   "source": [
    "Notesé que ya no calculamos MEAN y STD para normalizar aquí, si no que usamos los valores estandard (calculados por la comunidad) para rapidez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6bb1b2",
   "metadata": {},
   "source": [
    "Además no usaremos data-augmentation aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb148fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n",
      "[0.485, 0.456, 0.406]\n",
      "[0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "#Obtenemos los pesos de la red VGG16 entrenada en el dataset IMAGENET\n",
    "\n",
    "weights = models.VGG16_Weights.IMAGENET1K_V1\n",
    "\n",
    "#Como vemos aqui observamos los valores a los que nuestro dataset debe ser normalizado\n",
    "# y preprocesado para que la red pueda usarlo.\n",
    "\n",
    "preprocess = weights.transforms()\n",
    "print(preprocess)\n",
    "IMAGENET_MEAN = preprocess.mean\n",
    "IMAGENET_STD  = preprocess.std\n",
    "\n",
    "print(IMAGENET_MEAN)\n",
    "print(IMAGENET_STD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb4ec0",
   "metadata": {},
   "source": [
    "Como vemos arriba:\n",
    "\n",
    "### crop_size=[224]\n",
    "\n",
    "Es el tamaño final de la imagen que el modelo usa como entrada: 224×224 píxeles.\n",
    "Se consigue aplicando transforms.CenterCrop(224) después del resize.\n",
    "\n",
    "### resize_size=[256]\n",
    "\n",
    "Antes del recorte, la imagen se redimensiona de forma que su lado más corto mida 256 píxeles, manteniendo su proporción.\n",
    "Esto equivale a transforms.Resize(256)\n",
    "\n",
    "También observamos la media y desviación estandard que usaremos para la normalización.\n",
    "\n",
    "Este pipeline que hemos visto arriba, tenemos que replicarlo en nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Replicamos el pipeline de preprocesado de la red VGG16\n",
    "base_tf = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BILINEAR), # Redimensiona la imagen\n",
    "    transforms.CenterCrop(224), # Recorta la imagen\n",
    "    transforms.ToTensor(), # Convierte la imagen a un tensor\n",
    "    transforms.Normalize(weights.transforms().mean, weights.transforms().std), # Normaliza la imagen\n",
    "])\n",
    "\n",
    "root = \"./data/01\"\n",
    "train_ds = datasets.ImageFolder(f\"{root}/train\", transform=base_tf)\n",
    "valid_ds = datasets.ImageFolder(f\"{root}/valid\", transform=base_tf)\n",
    "test_ds  = datasets.ImageFolder(f\"{root}/test\",  transform=base_tf)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=64, shuffle=False)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=64, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
